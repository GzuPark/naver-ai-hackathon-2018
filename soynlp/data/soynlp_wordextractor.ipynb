{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordExtractor in soynlp\n",
    "\n",
    "가지고 있는 데이터를 활용하여 soynlp에서 제공하는 WordExtractor tutorial을 진행하였다.\n",
    "\n",
    "source: https://github.com/lovit/soynlp/blob/master/tutorials/wordextractor_lecture.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/soynlp\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  description.py  setup.py  soynlp_wordextractor.ipynb\r\n",
      "data\t   notes\t   soynlp    tutorials\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터는 인터넷에서 크롤링해온것\n",
    "data = pd.read_csv('data/sample.csv', header=0, encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movie_nm</th>\n",
       "      <th>score</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>프로메테우스</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2014.11.17</td>\n",
       "      <td>정리가 안되는 에일리언 시리즈를 리부트한 영화 그러나 외계인에 대한 공포감은 전작들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>지옥화</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014.11.17</td>\n",
       "      <td>배우들 연기도 좋고 시나리오도 좋고 여배우 진짜 고생했을듯 아쉬운점은 영화 전개가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>드라큘라: 전설의 시작</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014.11.17</td>\n",
       "      <td>어디서 낮이 있다 했는데 원조 드라큘라하고 아들은 왕좌의게임에 나온 사람이였네 ㅎㅎ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>인터스텔라</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.11.17</td>\n",
       "      <td>대단한영화다ㅡ최근몇년간흥미와감동을준것은ㅡ아바타이후로처음 ㅡ아바타보다오락성은떨어지나심...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>인터스텔라</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.11.17</td>\n",
       "      <td>내 생애 다시 이런 영화을 만나 볼수 있을까다시 만나 보고 싶다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      movie_nm  score    reg_date  \\\n",
       "0           1        프로메테우스    6.0  2014.11.17   \n",
       "1           2           지옥화    9.0  2014.11.17   \n",
       "2           3  드라큘라: 전설의 시작    9.0  2014.11.17   \n",
       "3           4         인터스텔라   10.0  2014.11.17   \n",
       "4           5         인터스텔라   10.0  2014.11.17   \n",
       "\n",
       "                                            comments  \n",
       "0  정리가 안되는 에일리언 시리즈를 리부트한 영화 그러나 외계인에 대한 공포감은 전작들...  \n",
       "1  배우들 연기도 좋고 시나리오도 좋고 여배우 진짜 고생했을듯 아쉬운점은 영화 전개가 ...  \n",
       "2  어디서 낮이 있다 했는데 원조 드라큘라하고 아들은 왕좌의게임에 나온 사람이였네 ㅎㅎ...  \n",
       "3  대단한영화다ㅡ최근몇년간흥미와감동을준것은ㅡ아바타이후로처음 ㅡ아바타보다오락성은떨어지나심...  \n",
       "4               내 생애 다시 이런 영화을 만나 볼수 있을까다시 만나 보고 싶다   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    정리가 안되는 에일리언 시리즈를 리부트한 영화 그러나 외계인에 대한 공포감은 전작들...\n",
       "1    배우들 연기도 좋고 시나리오도 좋고 여배우 진짜 고생했을듯 아쉬운점은 영화 전개가 ...\n",
       "2    어디서 낮이 있다 했는데 원조 드라큘라하고 아들은 왕좌의게임에 나온 사람이였네 ㅎㅎ...\n",
       "3    대단한영화다ㅡ최근몇년간흥미와감동을준것은ㅡ아바타이후로처음 ㅡ아바타보다오락성은떨어지나심...\n",
       "4                 내 생애 다시 이런 영화을 만나 볼수 있을까다시 만나 보고 싶다 \n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comments'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['comments'].to_csv('data/sample.txt', index=False, header=False, encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences = 44714\n"
     ]
    }
   ],
   "source": [
    "class Sentences:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.length = 0\n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='CP949') as f:\n",
    "            for doc in f:\n",
    "                doc = doc.strip()\n",
    "                if not doc:\n",
    "                    continue\n",
    "                for sent in doc.split('  '):\n",
    "                    yield sent\n",
    "    def __len__(self):\n",
    "        if self.length == 0:\n",
    "            with open(self.fname, encoding='CP949') as f:\n",
    "                for doc in f:\n",
    "                    doc = doc.strip()\n",
    "                    if not doc:\n",
    "                        continue\n",
    "                    self.length += len(doc.split('  '))\n",
    "        return self.length\n",
    "    \n",
    "corpus_fname = 'data/sample.txt'\n",
    "sentences = Sentences(corpus_fname)\n",
    "print('num sentences = %d' % len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.306 Gbory 0.090 Gb\n",
      "all cohesion probabilities was computed. # words = 2081\n",
      "all branching entropies was computed # words = 49532\n",
      "all accessor variety was computed # words = 49532\n",
      "CPU times: user 7.24 s, sys: 170 ms, total: 7.41 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(min_count=100,\n",
    "                               min_cohesion_forward=0.05, \n",
    "                               min_right_branching_entropy=0.0)\n",
    "\n",
    "word_extractor.train(sentences)\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.9197908301199416, cohesion_backward=0, left_branching_entropy=3.408236216765657, right_branching_entropy=0.34804303823242544, left_accessor_variety=38, right_accessor_variety=4, leftside_frequency=228, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['킬링타임']))\n",
    "print(words['킬링타임'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어   (빈도수, cohesion, branching entropy)\n",
      "\n",
      "영화     (20970, 0.946, 4.587)\n",
      "합니다     (249, 0.841, 4.613)\n",
      "너무     (3871, 0.967, 4.411)\n",
      "ㅠㅠ     (425, 0.924, 4.367)\n",
      "입니다     (128, 0.530, 4.726)\n",
      "ㅎㅎ     (523, 0.903, 4.016)\n",
      "ㅋㅋ     (1199, 0.968, 3.915)\n",
      "봤는데     (1155, 0.556, 4.459)\n",
      "뭔가     (492, 0.768, 4.059)\n",
      "된다     (248, 0.768, 4.058)\n",
      "진짜     (1437, 0.413, 4.678)\n",
      "정말     (2703, 0.536, 4.368)\n",
      "봤습니다     (492, 0.508, 4.385)\n",
      "역시     (741, 0.475, 4.420)\n",
      "때문에     (340, 0.645, 4.054)\n",
      "솔직히     (350, 0.882, 3.734)\n",
      "근데     (299, 0.584, 4.086)\n",
      "ㅜㅜ     (143, 0.941, 3.593)\n",
      "하지만     (726, 0.347, 4.567)\n",
      "그리고     (852, 0.294, 4.714)\n",
      "준다     (164, 0.588, 3.950)\n",
      "완전     (800, 0.638, 3.848)\n",
      "간만에     (275, 0.674, 3.713)\n",
      "ㅋㅋㅋ     (627, 0.711, 3.624)\n",
      "라는     (144, 0.372, 4.271)\n",
      "얼마나     (289, 0.712, 3.619)\n",
      "특히     (359, 0.438, 4.093)\n",
      "든다     (125, 0.874, 3.397)\n",
      "영화입니다     (475, 0.383, 4.181)\n",
      "함께     (470, 0.836, 3.391)\n"
     ]
    }
   ],
   "source": [
    "def word_score(score):\n",
    "    import math\n",
    "    return (score.cohesion_forward * math.exp(score.right_branching_entropy))\n",
    "\n",
    "print('단어   (빈도수, cohesion, branching entropy)\\n')\n",
    "for word, score in sorted(words.items(), key=lambda x:word_score(x[1]), reverse=True)[:30]:\n",
    "    print('%s     (%d, %.3f, %.3f)' % (word, \n",
    "                                   score.leftside_frequency, \n",
    "                                   score.cohesion_forward,\n",
    "                                   score.right_branching_entropy\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 많은 데이터를 가지고 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commentafter_12001to15000.csv  commentafter_39001to42000.csv\r\n",
      "commentafter_15001to18000.csv  commentafter_42001to45000.csv\r\n",
      "commentafter_18001to21000.csv  commentafter_45001to48000.csv\r\n",
      "commentafter_1to3000.csv       commentafter_48001to51000.csv\r\n",
      "commentafter_21001to24000.csv  commentafter_51001to54000.csv\r\n",
      "commentafter_24001to27000.csv  commentafter_54001to57000.csv\r\n",
      "commentafter_27001to30000.csv  commentafter_57001to60000.csv\r\n",
      "commentafter_30001to33000.csv  commentafter_60001to63000.csv\r\n",
      "commentafter_3001to6000.csv    commentafter_6001to9000.csv\r\n",
      "commentafter_33001to36000.csv  commentafter_63001to65000.csv\r\n",
      "commentafter_36001to39000.csv  commentafter_9001to12000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/moviereview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirpath = 'data/moviereview/'\n",
    "filelist = os.listdir(dirpath)\n",
    "isfirst = True\n",
    "\n",
    "for file in filelist:\n",
    "    try:\n",
    "        tmp = pd.read_csv(dirpath + file, header=0, encoding='CP949')\n",
    "        if isfirst:\n",
    "            data = tmp\n",
    "            isfirst = False\n",
    "        else:\n",
    "            data = data.append(tmp, ignore_index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930000\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['comments'].to_csv('data/moviereview.txt', index=False, header=False, encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences = 925337\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = 'data/moviereview.txt'\n",
    "sentences = Sentences(corpus_fname)\n",
    "print('num sentences = %d' % len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.525 Gbse memory 3.313 Gb\n",
      "all cohesion probabilities was computed. # words = 32821\n",
      "all branching entropies was computed # words = 492181\n",
      "all accessor variety was computed # words = 492181\n",
      "CPU times: user 2min 22s, sys: 1.87 s, total: 2min 24s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(min_count=100,\n",
    "                               min_cohesion_forward=0.05, \n",
    "                               min_right_branching_entropy=0.0)\n",
    "\n",
    "word_extractor.train(sentences)\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24995\n",
      "1536.09375  KB\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(len(words))\n",
    "print(getsizeof(words)/1024, ' KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.9069446565911313, cohesion_backward=0, left_branching_entropy=3.977275638579379, right_branching_entropy=0.6093567670846984, left_accessor_variety=159, right_accessor_variety=27, leftside_frequency=3689, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['킬링타임']))\n",
    "print(words['킬링타임'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어   (빈도수, cohesion, branching entropy)\n",
      "\n",
      "됩니다     (1161, 0.973, 5.043)\n",
      "합니다     (5247, 0.854, 5.157)\n",
      "든다     (1945, 0.908, 5.093)\n",
      "ㅡㅡ     (4441, 0.926, 4.971)\n",
      "영화     (452008, 0.948, 4.944)\n",
      "항상     (2060, 0.805, 5.025)\n",
      "ㅠㅠ     (14371, 0.944, 4.857)\n",
      "봅니다     (1527, 0.923, 4.858)\n",
      "ㅜㅜ     (4067, 0.914, 4.866)\n",
      "갑자기     (1871, 0.693, 5.100)\n",
      "ㅎㅎ     (13420, 0.930, 4.760)\n",
      "입니다     (3260, 0.598, 5.183)\n",
      "줍니다     (1071, 0.974, 4.679)\n",
      "텐데     (484, 0.883, 4.748)\n",
      "듭니다     (1037, 0.995, 4.625)\n",
      "근데     (8118, 0.680, 4.991)\n",
      "솔직히     (9106, 0.897, 4.702)\n",
      "뭔가     (10888, 0.803, 4.807)\n",
      "였습니다     (759, 0.619, 5.065)\n",
      "쵝오     (1902, 0.975, 4.604)\n",
      "너무     (98389, 0.981, 4.568)\n",
      "준다     (2653, 0.552, 5.136)\n",
      "차라리     (2928, 0.486, 5.254)\n",
      "역시     (20103, 0.566, 5.083)\n",
      "특히     (8344, 0.522, 5.127)\n",
      "된다     (3545, 0.672, 4.861)\n",
      "봤습니다     (12438, 0.520, 5.117)\n",
      "왔습니다     (2226, 0.631, 4.913)\n",
      "까지     (1578, 0.411, 5.343)\n",
      "갠적으로     (849, 0.845, 4.619)\n"
     ]
    }
   ],
   "source": [
    "def word_score(score):\n",
    "    import math\n",
    "    return (score.cohesion_forward * math.exp(score.right_branching_entropy))\n",
    "\n",
    "print('단어   (빈도수, cohesion, branching entropy)\\n')\n",
    "for word, score in sorted(words.items(), key=lambda x:word_score(x[1]), reverse=True)[:30]:\n",
    "    print('%s     (%d, %.3f, %.3f)' % (word, \n",
    "                                   score.leftside_frequency, \n",
    "                                   score.cohesion_forward,\n",
    "                                   score.right_branching_entropy\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성한 words dictionary를 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('data/moviereview.npy', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "words = 0\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일에서 words dictionary 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.load('data/moviereview.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24995\n",
      "1536.09375  KB\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(len(words))\n",
    "print(getsizeof(words)/1024, ' KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.9069446565911313, cohesion_backward=0, left_branching_entropy=3.977275638579379, right_branching_entropy=0.6093567670846984, left_accessor_variety=159, right_accessor_variety=27, leftside_frequency=3689, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['킬링타임']))\n",
    "print(words['킬링타임'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
